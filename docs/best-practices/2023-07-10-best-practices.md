---
layout: default
title:  "gpt best practices"
date:   2023-07-10
categories: openai best-practices
typora-root-url: ../../
parent: best-practices
---

# GPT best practices

​	这里分享了从GPT获取更好结果的策略和技巧。这里描述的方法有时可以组合使用以获得更大的效果。我们鼓励你进行试验，找出最适合你的方法。

​	这里展示的一些例子目前只适用于Open AI最强大的模型，即gpt-4。如果你还没有使用gpt-4的权限，[可以考虑加入等待名单](https://openai.com/waitlist/gpt-4-api)。总的来说，如果你发现一个GPT模型无法完成任务，并且有更强大的模型可用，那么常常值得再次使用更强大的模型尝试

## 获取期望结果的六种策略

### 编写清晰的指令 GPT 

​	不要让GPT尝试读取你的思绪。输出太长，你要求简短的回复。输出过于简单，你要求专家级别的写作。格式你不喜欢，要展示你想要看到的格式等等。说出来你想要的，GPT越少猜测你想要什么，你得到它的可能性就越大。

具体策略：

- 在你的查询中包含详细信息以获得更相关的答案
- 要求模型采用一种角色，比如 你是中英互译专家
- 使用分隔符清晰地表示输入的不同部分
- 指定完成任务所需的步骤
- 提供示例
- 指定期望的输出长度

## 提供参考文本

GPT在被问及深奥的主题或被要求提供引用和URL时，可能会自信地编造出虚假的答案。就像一张笔记可以帮助学生在测试中取得更好的成绩一样，向GPT提供参考文本可以帮助其以更少的编造来回答问题。

策略：

指示模型使用参考文本进行回答
指示模型引用参考文本进行回答

### 将复杂任务分解为更简单的子任务

正如在软件工程中将复杂系统分解为一组模块化组件是良好的实践，对GPT提交的任务也是如此。复杂任务的错误率往往比简单任务高。此外，复杂的任务常常可以被重新定义为一系列简单任务的工作流，其中早期任务的输出被用来构造后续任务的输入。

策略：

使用意图分类来确定用户查询的最相关指令
对需要进行很长对话的对话应用，对之前的对话进行总结或过滤
分段总结长文档，并递归地构造完整的总结

### 给GPT留出时间“思考”

如果被问到17乘以28，你可能不会立即知道答案，但还是可以花时间算出来。同样，GPT在试图立即回答，而不是花时间想出答案时，更容易犯推理错误。在回答之前要求一系列的推理过程可以帮助GPT更可靠地推理出正确的答案。

策略：

指示模型在急于得出结论之前先想出自己的解决方案
使用内心独白或一系列查询来隐藏模型的推理过程
询问模型在之前的步骤中是否漏掉了任何东西

### 使用外部工具

通过将其他工具的输出提供给GPT，来弥补GPT的弱点。例如，文本检索系统可以告诉GPT有关的文档。代码执行引擎可以帮助GPT做数学运算和运行代码。如果一个任务可以被一个工具比GPT更可靠或高效地完成，那么将其外包出去以便从中得到最好的结果。

策略：

使用基于嵌入的搜索来实现高效的知识检索
使用代码执行进行更准确的计算或调用外部API
让模型能够访问特定的功能

### 系统地测试更改

如果你可以衡量性能，那么提高性能就会更容易。在某些情况下，对提示的修改可能会在几个孤立的例子上获得更好的性能，但在更具代表性的一组例子上导致整体性能下降。因此，为了确定改变对性能的净效应是正面的，可能需要定义一个全面的测试套件（也被称为“评估”）。

策略：

根据金标准答案评估模型的输出
